{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1AA6h_27J_4FaP2KkBxfwJljrBIxIWNpJ","authorship_tag":"ABX9TyMai8uLjozNYp+QNwuSIlXh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install cohere\n","!pip install chromadb\n","!pip install langchain\n","!pip install llama-index\n","!pip install jq\n","!pip install ragas"],"metadata":{"id":"5UrOZa-GvH7q"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qZ3iIcgumUe"},"outputs":[],"source":["import os\n","import openai\n","import sys\n","sys.path.append('../..')\n","\n","from dotenv import load_dotenv, find_dotenv\n","_ = load_dotenv(find_dotenv()) # read local .env file\n","#OpenAI Key\n","os.environ['OPENAI_API_KEY'] = \"KEY\"\n","openai.api_key  = os.environ['OPENAI_API_KEY']\n","\n","#cohere Keys\n","os.environ[\"COHERE_API_KEY\"] = \"KEY\""]},{"cell_type":"markdown","source":["## Document loading"],"metadata":{"id":"EzJTFRlSxPbX"}},{"cell_type":"code","source":["# Loading whole arabic Wikipedia\n","from langchain.document_loaders.csv_loader import CSVLoader\n","import json\n","from pathlib import Path\n","from pprint import pprint\n","import sys\n","import csv\n","\n","csv.field_size_limit(sys.maxsize)\n","\n","path='articles_V3.csv'\n","loader = CSVLoader(file_path=path, source_column=\"title\")\n","\n","data = loader.load()\n","\n","\n"],"metadata":{"id":"hGlkKPBwxRjg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Vectore Store and Embeddings"],"metadata":{"id":"0fzrEQWh_L_Z"}},{"cell_type":"code","source":["from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n","from langchain.embeddings import CohereEmbeddings, OpenAIEmbeddings\n","from langchain.vectorstores import Chroma\n","from langchain.indexes import VectorstoreIndexCreator\n","import cohere\n","\n","r_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=2000,\n","    chunk_overlap=400,\n","    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"])\n","\n","# Using wrapper\n","\n","index_creator = VectorstoreIndexCreator(\n","    vectorstore_cls=Chroma,\n","    embedding= OpenAIEmbeddings(model='text-embedding-ada-002'),\n","    #text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","    text_splitter= r_splitter\n",")\n"],"metadata":{"id":"_k2uLAXrAgwW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from langchain.chains import RetrievalQA\n","from langchain.chat_models import ChatOpenAI\n","from langchain.llms import Cohere\n","\n","\n","# Create index\n","index = index_creator.from_loaders([loader])\n","\n","\n"],"metadata":{"id":"k-sosPgq_RDz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### QA Chain"],"metadata":{"id":"6AHuatLkE16H"}},{"cell_type":"code","source":["from langchain.chains import RetrievalQA\n","from ragas.metrics import faithfulness, answer_relevancy, context_relevancy, context_recall\n","from ragas.langchain import RagasEvaluatorChain\n","import pandas as pd\n","import csv\n","\n","\n","\n","#cohere LM\n","llm = Cohere(cohere_api_key=os.environ[\"COHERE_API_KEY\"], model= \"command-nightly\")\n","\n","\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm, retriever=index.vectorstore.as_retriever(), return_source_documents=True\n",")\n","# load questiosn and answers\n","dataset = pd.read_json('/content/drive/MyDrive/RAG_Eman_code/dataset/rag_KaifLematha.json')\n","\n","\n","# file name represents llm_embedding_questionSource_contextSource\n","filename = f\"Cohere_OpenAI_KaifLemathaQ_KaifLemathaC_2.csv\"\n","\n","faith=[]\n","ans_relevancy =[]\n","cont_relevancy =[]\n","cont_recall =[]\n","\n","# write evaluation metric into csv file\n","with open(filename, 'a', newline='') as f:\n"," writer = csv.writer(f)\n"," writer.writerow(['Query', 'reponse', 'faithfulness','answer_relevancy','context_relevancy','context_recall'])\n","\n","  #iterate through  questions from dataset file\n"," for index, row in dataset.iterrows():\n","  try:\n","     # answer question using document and ChatGPT3.5\n","     result = qa_chain({\"query\": row['question']})\n","     #print(result[\"result\"])\n","\n","     result['ground_truths'] = [row['answer'] ]\n","\n","     # make eval chains\n","     eval_chains = {\n","       m.name: RagasEvaluatorChain(metric=m)\n","       for m in [faithfulness, answer_relevancy, context_relevancy, context_recall]}\n","\n","\n","     # write scores to CSV file\n","     scores= []\n","     for name, eval_chain in eval_chains.items():\n","                score_name = f\"{name}_score\"\n","                scores.append(eval_chain(result)[score_name])\n","     writer.writerow([result['query'],\n","                        result['result'],\n","                             str(scores[0]), str(scores[1]), str(scores[2]),str(scores[3])])\n","     faith.append(str(scores[0]))\n","     ans_relevancy.append(str(scores[1]))\n","     cont_relevancy.append(str(scores[2]))\n","     cont_recall.append(str(scores[3]))\n","\n","  except:\n","\n","        print(\"Whew!\", sys.exc_info()[0], \"occurred.\")\n","\n","        print(\"Next input please.\")\n","\n","\n","\n","\n"],"metadata":{"id":"3-Viw7ZuPI1V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["average_faith = sum(faith) / len(faith)\n","average_ans_relevancy = sum(ans_relevancy) / len(ans_relevancy)\n","average_cont_relevancy = sum(cont_relevancy) / len(cont_relevancy)\n","average_cont_recall = sum(cont_recall) / len(cont_recall)\n","\n","print(\"average_faithfulness \"+ average_faith)\n","print(\"average_ans_relevancy \"+ average_ans_relevancy)\n","print(\"average_cont_relevancy \"+ average_cont_relevancy)\n","print(\"average_cont_recall \"+ average_cont_recall)"],"metadata":{"id":"bhQpMRFVgBU9"},"execution_count":null,"outputs":[]}]}
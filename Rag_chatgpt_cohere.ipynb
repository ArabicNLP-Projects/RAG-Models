{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1gnIq4x4gP_VYAza7mwBczF-iC1sN7h5V","authorship_tag":"ABX9TyOBsRGkyZ0Rn+UhEFdf9oqr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install cohere\n","!pip install chromadb\n","!pip install langchain\n","!pip install llama-index\n","!pip install jq\n","!pip install ragas"],"metadata":{"id":"5UrOZa-GvH7q"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qZ3iIcgumUe"},"outputs":[],"source":["import os\n","import openai\n","import sys\n","sys.path.append('../..')\n","\n","from dotenv import load_dotenv, find_dotenv\n","_ = load_dotenv(find_dotenv()) # read local .env file\n","#OpenAI Key\n","os.environ['OPENAI_API_KEY'] = \"KEY\"\n","openai.api_key  = os.environ['OPENAI_API_KEY']\n","\n","#cohere Keys\n","os.environ[\"COHERE_API_KEY\"] = \"KEY\""]},{"cell_type":"markdown","source":["## Document loading"],"metadata":{"id":"EzJTFRlSxPbX"}},{"cell_type":"code","source":["\n","# Loading whole arabic Wikipedia\n","from langchain.document_loaders.csv_loader import CSVLoader\n","import json\n","from pathlib import Path\n","from pprint import pprint\n","import sys\n","import csv\n","\n","csv.field_size_limit(sys.maxsize)\n","\n","path='articles_V3.csv'\n","loader = CSVLoader(file_path=path, source_column=\"title\")\n","\n","data = loader.load()\n","\n","\n","print(data[0])\n"],"metadata":{"id":"hGlkKPBwxRjg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Vectore Store and Embeddings"],"metadata":{"id":"0fzrEQWh_L_Z"}},{"cell_type":"code","source":["from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n","from langchain.embeddings import CohereEmbeddings\n","from langchain.vectorstores import Chroma\n","from langchain.indexes import VectorstoreIndexCreator\n","import cohere\n","\n","r_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=2000,\n","    chunk_overlap=400,\n","    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"])\n","\n","\n","# Using wrapper\n","\n","index_creator = VectorstoreIndexCreator(\n","    vectorstore_cls=Chroma,\n","    embedding=CohereEmbeddings(model=\"embed-multilingual-v2.0\"),\n","    #text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","    text_splitter= r_splitter\n",")\n"],"metadata":{"id":"_k2uLAXrAgwW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from langchain.chains import RetrievalQA\n","from langchain.chat_models import ChatOpenAI\n","\n","# Create index\n","index = index_creator.from_loaders([loader])\n","\n","\n"],"metadata":{"id":"k-sosPgq_RDz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### QA Chain"],"metadata":{"id":"6AHuatLkE16H"}},{"cell_type":"code","source":["from langchain.chains import RetrievalQA\n","from ragas.metrics import faithfulness, answer_relevancy, context_relevancy, context_recall\n","from ragas.langchain import RagasEvaluatorChain\n","import pandas as pd\n","import csv\n","\n","\n","# create the QA chain\n","llm = ChatOpenAI(model= \"gpt-3.5-turbo\")\n","qa_chain = RetrievalQA.from_chain_type(\n","    llm, retriever=index.vectorstore.as_retriever(), return_source_documents=True\n",")\n","# load questiosn and answers\n","dataset = pd.read_json('/dataset/rag_KaifLematha.json')\n","\n","\n","# file name represents llm_embedding_questionSource_contextSource\n","filename = f\"ChatGPT_Cohere_KaifLemathaQ_KaifLemathaC.csv\"\n","\n","faith=[]\n","ans_relevancy =[]\n","cont_relevancy =[]\n","cont_recall =[]\n","\n","# write evaluation metric into csv file\n","with open(filename, 'a', newline='') as f:\n"," writer = csv.writer(f)\n"," writer.writerow(['Query', 'reponse', 'faithfulness','answer_relevancy','context_relevancy','context_recall'])\n","\n","  #iterate through  questions from dataset file\n"," for index, row in dataset.iterrows():\n","  try:\n","     # answer question using document and ChatGPT3.5\n","     result = qa_chain({\"query\": row['question']})\n","     # print(result[\"result\"])\n","\n","     result['ground_truths'] = [row['answer'] ]\n","\n","     # make eval chains\n","     eval_chains = {\n","       m.name: RagasEvaluatorChain(metric=m)\n","       for m in [faithfulness, answer_relevancy, context_relevancy, context_recall]}\n","\n","\n","     # write scores to CSV file\n","     scores= []\n","     for name, eval_chain in eval_chains.items():\n","                score_name = f\"{name}_score\"\n","                scores.append(eval_chain(result)[score_name])\n","     writer.writerow([result['query'],\n","                        result['result'],\n","                             str(scores[0]), str(scores[1]), str(scores[2]),str(scores[3])])\n","     faith.append(str(scores[0]))\n","     ans_relevancy.append(str(scores[1]))\n","     cont_relevancy.append(str(scores[2]))\n","     cont_recall.append(str(scores[3]))\n","\n","  except:\n","\n","        print(\"Whew!\", sys.exc_info()[0], \"occurred.\")\n","\n","        print(\"Next input please.\")\n"],"metadata":{"id":"3-Viw7ZuPI1V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["average_faith = sum(faith) / len(faith)\n","average_ans_relevancy = sum(ans_relevancy) / len(ans_relevancy)\n","average_cont_relevancy = sum(cont_relevancy) / len(cont_relevancy)\n","average_cont_recall = sum(cont_recall) / len(cont_recall)\n","\n","print(\"average_faithfulness \"+ average_faith)\n","print(\"average_ans_relevancy \"+ average_ans_relevancy)\n","print(\"average_cont_relevancy \"+ average_cont_relevancy)\n","print(\"average_cont_recall \"+ average_cont_recall)"],"metadata":{"id":"jXBz8-wuf396"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"2gDRty7RkbFT"}},{"cell_type":"code","source":["from numpy import double\n","import pandas as pd\n","# loading metrics file\n","data= pd.read_csv(\"/Cohere_OpenAI_KaifLemathaQ_KaifLemathaC_2.csv\")\n","# averaging over 4 mertices'faithfulness','answer_relevancy','context_relevancy','context_recall'\n","\n","# Use the `to_numeric()` function to convert the column to floats\n","data['faithfulness'] = pd.to_numeric(data['faithfulness'], errors='coerce')\n","data['answer_relevancy'] = pd.to_numeric(data['answer_relevancy'], errors='coerce')\n","data['context_relevancy'] = pd.to_numeric(data['context_relevancy'], errors='coerce')\n","data['context_recall'] = pd.to_numeric(data['context_recall'], errors='coerce')\n","\n","avg_faithfulness= data['faithfulness'].mean()\n","avg_answer_relevancy= data['answer_relevancy'].mean()\n","avg_context_relevancy= data['context_relevancy'].mean()\n","avg_context_recall= data['context_recall'].mean()\n","\n","print(\"avg faithfulness \"+ str(avg_faithfulness))\n","print(\"avg answer_relevancy \"+ str(avg_answer_relevancy))\n","print(\"avg context_relevancy \"+ str(avg_context_relevancy))\n","print(\"avg context_recall \"+ str(avg_context_recall))\n","\n","ragas_score= 4/(1/avg_faithfulness + 1/avg_answer_relevancy + 1/avg_context_relevancy + 1/avg_context_recall)\n","\n","\n","print(ragas_score)\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bKH-oaSF389x","executionInfo":{"status":"ok","timestamp":1694752822877,"user_tz":-180,"elapsed":515,"user":{"displayName":"Eman Albilali","userId":"09562528622542556593"}},"outputId":"743d69e7-4668-4605-ad66-3daa685fb4f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["avg faithfulness 0.4270867251369851\n","avg answer_relevancy 0.7476081613848187\n","avg context_relevancy 0.06355780928364357\n","avg context_recall 0.4889077587037799\n","0.18640955664884606\n"]}]}]}